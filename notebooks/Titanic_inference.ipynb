{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7540cb1e-8919-47f9-8b95-687d668f0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from scipy.stats import skew, sem, t\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2693ce48-1eb6-48e6-bc88-38f102083c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc3efe-bc02-4771-95da-d84334df5d70",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b09fbc0-21b7-4902-bff2-1aa219e42425",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9422d7d1-6ad5-4d8c-95a8-1c63946336cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39eb867-0645-4bb9-b21a-26f2a4dc0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd566f1-3dae-4761-a15b-0f033ba1010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492173ac-2b88-4ec3-9414-741c3311f1ca",
   "metadata": {},
   "source": [
    "# Missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203f2ca4-8ccf-4030-859a-87aebca4550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median ages by Pclass\n",
    "median_age_Pclass1 = df[df['Pclass']==1]['Age'].median()\n",
    "median_age_Pclass2 = df[df['Pclass']==2]['Age'].median()\n",
    "median_age_Pclass3 = df[df['Pclass']==3]['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0768af0-912d-4474-8cf7-87ffa675e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(data):\n",
    "    \"\"\"\n",
    "    Function to impute missing 'Age' values based on 'Pclass'.\n",
    "\n",
    "    This function imputes missing 'Age' values using the median age\n",
    "    for each 'Pclass' (passenger class):\n",
    "    - Pclass 1: Uses median_age_Pclass1\n",
    "    - Pclass 2: Uses median_age_Pclass2\n",
    "    - Pclass 3: Uses median_age_Pclass3\n",
    "    If the 'Age' is not missing, it returns the original value.\n",
    "\n",
    "    Parameters:\n",
    "    data (Series): A row of the Titanic dataset with columns 'Age' and 'Pclass'.\n",
    "\n",
    "    Returns:\n",
    "    float: The imputed or original 'Age' value.\n",
    "    \"\"\"\n",
    "    \n",
    "    Age = data['Age']\n",
    "    Pclass = data['Pclass']\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        if Pclass == 1:\n",
    "            return median_age_Pclass1\n",
    "        elif Pclass == 2:\n",
    "            return median_age_Pclass2\n",
    "        else:\n",
    "            return median_age_Pclass3\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ba9512-d668-446c-b68d-f5d5aa9882b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_titanic(data):\n",
    "    \"\"\"\n",
    "    Imputes missing values in 'Age', 'Cabin', and other columns.\n",
    "    \n",
    "    - 'Age' is filled using median values by 'Pclass'.\n",
    "    - 'Cabin' is filled with 'U' for unknown.\n",
    "    - Any remaining missing values are dropped.\n",
    "\n",
    "    Parameters:\n",
    "    data (DataFrame): Titanic dataset.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Dataset with missing values handled.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['Age'] = data.apply(impute_age, axis=1)\n",
    "    data['Cabin'] = data['Cabin'].fillna('U')\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894ac02-1e3f-46cc-89f0-71bbb79c5a02",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb1bdf6-4a8c-4af2-b5b0-3f14effd3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data):\n",
    "    \"\"\"\n",
    "    Function to generate additional features for the Titanic dataset.\n",
    "    \n",
    "    This function creates new features such as 'Title', 'FamilySize', and 'Deck' by transforming \n",
    "    existing columns. It extracts 'Title' from 'Name', computes 'FamilySize' using 'SibSp' and \n",
    "    'Parch', and extracts the deck level from 'Cabin'. Additionally, unnecessary columns are \n",
    "    dropped after feature extraction.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): The Titanic dataset.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The modified dataset with newly generated features and redundant columns removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract 'Title' from 'Name' column\n",
    "    data['Title'] = data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "    # Create 'FamilySize' from 'SibSp' + 'Parch' + 1 (including the individual)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "    # Extract the first letter from 'Cabin' column to create 'Deck' feature\n",
    "    # If 'Cabin' is missing, the deck is assigned as 'U' for unknown\n",
    "    data['Deck'] = data['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'U')\n",
    "\n",
    "    # Drop original columns\n",
    "    data.drop(['SibSp','Parch','Cabin','Name'], axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b459b8-6ba1-44d7-b3f7-dfce3407d17a",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ca1408-9740-421b-b6ac-06b82d870f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mappings for configs\n",
    "\n",
    "title_mapping = {\"Master\":1, \"Miss\":2, \"Mr\":3, \"Mrs\":4, \"Dr\":5, \"Rev\":6}\n",
    "\n",
    "deck_mapping =  {\n",
    "    'A': 1,  \n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F': 6,\n",
    "    'G': 7,  \n",
    "    'T': 8,  \n",
    "    'U': 0   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e34e6b-a3e8-4c24-9ecb-d80ba0f745dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoding(data):\n",
    "    \"\"\"\n",
    "    Encodes 'Title' and 'Deck' columns using predefined mappings and drops the originals.\n",
    "\n",
    "    Parameters:\n",
    "    data : pandas.DataFrame\n",
    "        Input DataFrame with 'Title' and 'Deck' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        DataFrame with encoded 'Title' and 'Deck' columns as '_encoded'.\n",
    "    \"\"\"\n",
    "    mappings = {\n",
    "        'Title': title_mapping,\n",
    "        'Deck': deck_mapping\n",
    "    }\n",
    "\n",
    "    ordinal_columns = ['Title', 'Deck']\n",
    "\n",
    "    for column in ordinal_columns:\n",
    "        data[column + '_encoded'] = data[column].map(lambda x: mappings[column].get(x, 0))\n",
    "        data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebe065-c8b4-4f4a-850b-69cec27d500c",
   "metadata": {},
   "source": [
    "# Processing Continuos Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c69f14d-10ca-4ac7-9ec2-3a1d04963034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_fare(data):\n",
    "    \"\"\"\n",
    "    Log-transform the 'Fare' column and drop the original.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): Titanic dataset.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Dataset with 'Fare_log' and without 'Fare'.\n",
    "    \"\"\"\n",
    "    data['Fare_log'] = np.log1p(data['Fare'])\n",
    "    data.drop(['Fare'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9ff35-449d-4e74-884a-b704db1eb65f",
   "metadata": {},
   "source": [
    "# Scale Age and Fare_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649b1572-8804-4075-98c8-6b3522376e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_continuous_features(data):\n",
    "    \"\"\"\n",
    "    Scales the 'Age' and 'Fare_log' columns using a pre-fitted scaler.\n",
    "\n",
    "    Parameters:\n",
    "    data : pandas.DataFrame\n",
    "        Input data containing the columns to scale.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        DataFrame with scaled 'Age' and 'Fare_log' columns.\n",
    "    \"\"\"\n",
    "    columns_to_scale = ['Age', 'Fare_log']\n",
    "    scaler_loaded = joblib.load('../models/scaler.pkl')\n",
    "    data[columns_to_scale] = scaler_loaded.transform(data[columns_to_scale])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702da5f-51e3-426d-82f6-8d1c763de693",
   "metadata": {},
   "source": [
    "# Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f07d0b92-d696-4f32-b822-96cb02e03616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the Titanic dataset by handling missing values, \n",
    "    feature engineering, encoding, log transforming, and scaling features.\n",
    "    \"\"\"\n",
    "    # Drop features that were not used in the final version of the model\n",
    "    data.drop(['Embarked', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "    # Handle missing values\n",
    "    data = impute_missing_values_titanic(data)\n",
    "\n",
    "    # Feature engineering\n",
    "    data = generate_features(data)\n",
    "\n",
    "    # One-hot encoding for categorical variables\n",
    "    data = pd.get_dummies(data, columns=['Sex'], drop_first=True)\n",
    "\n",
    "    # Ordinal encoding for ordinal features\n",
    "    data = ordinal_encoding(data)\n",
    "\n",
    "    # Log transformation for skewed continuous variables\n",
    "    data = log_transform_fare(data)\n",
    "    \n",
    "    # Scale continuous features for normalization\n",
    "    data = scale_continuous_features(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b08a988e-0aaf-49d7-9910-c0bb6a91c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f2bd6-fa98-4d80-b8f0-8a513919d7fb",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5b333-a97c-45e6-8985-3653959ca547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dac72-b4a1-402f-a49a-892041f49749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(data):\n",
    "    \"\"\"\n",
    "    Generates predictions using a pre-trained Random Forest model and appends the results to a DataFrame.\n",
    "\n",
    "    This function loads the pre-trained model, extracts the relevant model features from the input data,\n",
    "    applies a custom probability threshold for classification, and generates predictions. The results are\n",
    "    stored in a DataFrame along with 'PassengerId' and the current run date.\n",
    "\n",
    "    If this function were running in a production environment (e.g., connected to a table in S3 or a database), \n",
    "    the results would need to be appended to an existing table rather than overwriting it. In such a scenario, \n",
    "    the function could be adapted to upload the results to S3 or a database by connecting to the appropriate \n",
    "    data storage service and appending the new predictions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        The input DataFrame containing the features used for making predictions.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame with three columns:\n",
    "        - 'PassengerId': The ID of each passenger.\n",
    "        - 'Prediction': The predicted survival outcome based on the custom threshold.\n",
    "        - 'RunDate': The date the pipeline was run.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get from config\n",
    "    model_features = ['Pclass', 'Age', 'FamilySize', 'Sex_male',\n",
    "       'Title_encoded', 'Deck_encoded', 'Fare_log']\n",
    "    \n",
    "    passenger_ids = data['PassengerId']\n",
    "\n",
    "    best_cutoff_threshold = 0.4012526976185753\n",
    "    \n",
    "    # Load model\n",
    "    with open('../models/titanic_RandomForestClassifier_full.pkl', 'rb') as file:\n",
    "        optimized_model_full = pickle.load(file)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    y_pred_prob = optimized_model_full.predict_proba(data[model_features])[:, 1]  \n",
    "\n",
    "    # Apply the custom threshold\n",
    "    y_pred_custom = (y_pred_prob >= best_cutoff_threshold).astype(int)\n",
    "\n",
    "    # Get the current date when the pipeline is run\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    #Create a DataFrame for the output\n",
    "    output_df = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Prediction': y_pred_custom,\n",
    "    'RunDate': current_date\n",
    "    })\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85375bc-7394-4750-b2b1-482e67e7580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop passenger ID for inference\n",
    "output = generate_predictions(df)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfc163-9774-4f7f-852c-2995759e199c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c43d00-4775-4a1e-b9d9-c3275b334cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
